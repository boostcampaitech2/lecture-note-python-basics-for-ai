{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0812a270",
   "metadata": {},
   "source": [
    "## Saving and Loading Model \n",
    "\n",
    "https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4355266",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "927a21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(3 * 3 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c816c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = TheModelClass()\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a61a962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "layer1.0.weight \t torch.Size([16, 3, 3, 3])\n",
      "layer1.0.bias \t torch.Size([16])\n",
      "layer1.1.weight \t torch.Size([16])\n",
      "layer1.1.bias \t torch.Size([16])\n",
      "layer1.1.running_mean \t torch.Size([16])\n",
      "layer1.1.running_var \t torch.Size([16])\n",
      "layer1.1.num_batches_tracked \t torch.Size([])\n",
      "layer2.0.weight \t torch.Size([32, 16, 3, 3])\n",
      "layer2.0.bias \t torch.Size([32])\n",
      "layer2.1.weight \t torch.Size([32])\n",
      "layer2.1.bias \t torch.Size([32])\n",
      "layer2.1.running_mean \t torch.Size([32])\n",
      "layer2.1.running_var \t torch.Size([32])\n",
      "layer2.1.num_batches_tracked \t torch.Size([])\n",
      "layer3.0.weight \t torch.Size([64, 32, 3, 3])\n",
      "layer3.0.bias \t torch.Size([64])\n",
      "layer3.1.weight \t torch.Size([64])\n",
      "layer3.1.bias \t torch.Size([64])\n",
      "layer3.1.running_mean \t torch.Size([64])\n",
      "layer3.1.running_var \t torch.Size([64])\n",
      "layer3.1.num_batches_tracked \t torch.Size([])\n",
      "fc1.weight \t torch.Size([1000, 576])\n",
      "fc1.bias \t torch.Size([1000])\n",
      "fc2.weight \t torch.Size([1, 1000])\n",
      "fc2.bias \t torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8906186",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e87ea095",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH =\"saved\"\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    os.makedirs(MODEL_PATH)\n",
    "torch.save(model.state_dict(), \n",
    "           os.path.join(MODEL_PATH, \"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6feb3ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "new_model = TheModelClass()\n",
    "new_model.load_state_dict(torch.load(os.path.join(\n",
    "    MODEL_PATH, \"model.pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f35421",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, os.path.join(MODEL_PATH, \"model.pt\"))\n",
    "model = torch.load(os.path.join(MODEL_PATH, \"model.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff1141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "filename = \"kagglecatsanddogs_3367a.zip\"\n",
    "with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "\n",
    "import shutil\n",
    "shutil.move('PetImages', 'data')\n",
    "\n",
    "import os\n",
    "from os import walk\n",
    "\n",
    "mypath = \"data\"\n",
    "\n",
    "f_path = []\n",
    "for (dirpath, dirnames, filenames) in walk(mypath):\n",
    "    f_path.extend([os.path.join(dirpath, filename) for filename in filenames])\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "for f_name in f_path:\n",
    "    try:\n",
    "        Image.open(f_name)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        os.remove(f_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8907168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"data/\",\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(244),       \n",
    "                               transforms.CenterCrop(244),  \n",
    "                               transforms.ToTensor(),       \n",
    "                               transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                    (0.5, 0.5, 0.5)), \n",
    "                           ]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=8,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f86f770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8828dc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1e7adc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_67264/3250662117.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6af0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "        y_pred = model(X_batch)\n",
    "               \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "        \n",
    "    torch.save({\n",
    "        'epoch': e,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': epoch_loss,\n",
    "        }, f\"saved/checkpoint_model_{e}_{epoch_loss/len(dataloader)}_{epoch_acc/len(dataloader)}.pt\")\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(dataloader):.5f} | Acc: {epoch_acc/len(dataloader):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0184237",
   "metadata": {},
   "source": [
    "## Pretrained Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769011c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "vgg = models.vgg16(pretrained=True).to(device)\n",
    "print(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68150d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(vgg, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd842505",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, layer in vgg.named_modules():\n",
    "    print(name, layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf285d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.fc = torch.nn.Linear(1000, 1)\n",
    "vgg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = models.vgg16(pretrained=True).to(device)\n",
    "print(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0258e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.classifier._modules['6'] = torch.nn.Linear(4096, 1)\n",
    "vgg.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872628de",
   "metadata": {},
   "source": [
    "## Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4dd9d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "dataset = datasets.ImageFolder(root=\"data/\",\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Scale(244),       \n",
    "                               transforms.CenterCrop(244),  \n",
    "                               transforms.ToTensor(),       \n",
    "                               transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                    (0.5, 0.5, 0.5)), \n",
    "                           ]))\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=2,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ea81f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "class MyNewNet(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(MyNewNet, self).__init__()\n",
    "        self.vgg19 = models.vgg19(pretrained=True)\n",
    "        self.linear_layers = nn.Linear(1000, 1)\n",
    "\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.vgg19(x)        \n",
    "        return self.linear_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ac5c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "my_model = MyNewNet()\n",
    "my_model = my_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7922679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNewNet(\n",
      "  (vgg19): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace=True)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace=True)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace=True)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace=True)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace=True)\n",
      "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (17): ReLU(inplace=True)\n",
      "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace=True)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace=True)\n",
      "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (24): ReLU(inplace=True)\n",
      "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (26): ReLU(inplace=True)\n",
      "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace=True)\n",
      "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (31): ReLU(inplace=True)\n",
      "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (33): ReLU(inplace=True)\n",
      "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (35): ReLU(inplace=True)\n",
      "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential(\n",
      "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Dropout(p=0.5, inplace=False)\n",
      "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "      (4): ReLU(inplace=True)\n",
      "      (5): Dropout(p=0.5, inplace=False)\n",
      "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (linear_layers): Linear(in_features=1000, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd45b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in my_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b553dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in my_model.linear_layers.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b7d0396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyNewNet(\n",
       "  (vgg19): VGG(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (17): ReLU(inplace=True)\n",
       "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (24): ReLU(inplace=True)\n",
       "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (26): ReLU(inplace=True)\n",
       "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (31): ReLU(inplace=True)\n",
       "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (33): ReLU(inplace=True)\n",
       "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (35): ReLU(inplace=True)\n",
       "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Dropout(p=0.5, inplace=False)\n",
       "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (linear_layers): Linear(in_features=1000, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a799c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2482d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model(x[0].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc2b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "06513ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e4ccc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(root=\"data/\",\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Scale(244),       \n",
    "                               transforms.CenterCrop(244),  \n",
    "                               transforms.ToTensor(),       \n",
    "                               transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                    (0.5, 0.5, 0.5)), \n",
    "                           ]))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f411c5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0535, -0.0493, -0.0679],\n",
       "         [ 0.0153,  0.0451,  0.0021],\n",
       "         [ 0.0362,  0.0200,  0.0199]],\n",
       "\n",
       "        [[ 0.0170,  0.0554, -0.0062],\n",
       "         [ 0.1416,  0.2271,  0.1376],\n",
       "         [ 0.1200,  0.2003,  0.0921]],\n",
       "\n",
       "        [[-0.0449,  0.0127, -0.0145],\n",
       "         [ 0.0597,  0.1395,  0.0541],\n",
       "         [-0.0010,  0.0583, -0.0297]]], device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(my_model.vgg19.features._modules['0'].parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1523705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0014,  0.0042, -0.0003,  0.0229, -0.0030, -0.0035, -0.0208, -0.0211,\n",
       "         0.0057,  0.0253], device='cuda:0', grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = my_model.linear_layers.parameters()\n",
    "next(it)[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b6eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "\n",
    "my_model = MyNewNet()\n",
    "my_model = my_model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(my_model.parameters(), lr=LEARNING_RATE)\n",
    "for param in my_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in my_model.linear_layers.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "\n",
    "for e in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).type(torch.cuda.FloatTensor)\n",
    "        \n",
    "        optimizer.zero_grad()        \n",
    "        y_pred = my_model(X_batch)\n",
    "               \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(dataloader):.5f} | Acc: {epoch_acc/len(dataloader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805af5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(my_model.vgg19.features._modules['0'].parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb839a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = my_model.linear_layers.parameters()\n",
    "next(it)[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56537ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
